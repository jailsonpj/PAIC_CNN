{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7f0fe08fd278>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation,Convolution2D, Dropout,Conv2D\n",
    "from keras.layers import AveragePooling2D,BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "#from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convenet():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32,(3,3),activation='relu',\n",
    "                       input_shape=(150,150,3)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape,num_classes=1):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('sigmoid',name='predictions'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN((150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_array (Conv2D)         (None, 150, 150, 16)      2368      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 16)      12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 150, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 38, 38, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 38, 38, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 38, 38, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 38, 38, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 19, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 1)         2305      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 630,673\n",
      "Trainable params: 629,201\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(INIT_LR), loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'cats_and_dogs_small/train',\n",
    "        target_size = (150,150),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'cats_and_dogs_small/validation',\n",
    "        target_size = (150,150),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 605s 6s/step - loss: 0.6711 - acc: 0.5781 - val_loss: 0.6684 - val_acc: 0.5871\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 581s 6s/step - loss: 0.6578 - acc: 0.6125 - val_loss: 0.6800 - val_acc: 0.5401\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.6529 - acc: 0.6156 - val_loss: 0.6365 - val_acc: 0.6197\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.6384 - acc: 0.6284 - val_loss: 0.7449 - val_acc: 0.4781\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.6232 - acc: 0.6525 - val_loss: 0.9109 - val_acc: 0.4793\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.6121 - acc: 0.6697 - val_loss: 0.5654 - val_acc: 0.6880\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.6087 - acc: 0.6600 - val_loss: 0.7353 - val_acc: 0.5877\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5888 - acc: 0.6919 - val_loss: 0.7216 - val_acc: 0.5526\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.5902 - acc: 0.6872 - val_loss: 0.5740 - val_acc: 0.6642\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.5894 - acc: 0.6853 - val_loss: 0.5911 - val_acc: 0.6673\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.5714 - acc: 0.7047 - val_loss: 0.7799 - val_acc: 0.5677\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5700 - acc: 0.7063 - val_loss: 0.5479 - val_acc: 0.7293\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.5711 - acc: 0.7056 - val_loss: 0.9030 - val_acc: 0.5088\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5679 - acc: 0.7047 - val_loss: 0.5248 - val_acc: 0.7281\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5516 - acc: 0.7141 - val_loss: 0.8235 - val_acc: 0.5407\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5613 - acc: 0.7113 - val_loss: 0.7008 - val_acc: 0.5854\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5392 - acc: 0.7303 - val_loss: 0.7572 - val_acc: 0.5520\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5376 - acc: 0.7353 - val_loss: 0.5290 - val_acc: 0.7325\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5472 - acc: 0.7269 - val_loss: 0.7564 - val_acc: 0.6115\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5305 - acc: 0.7384 - val_loss: 0.7515 - val_acc: 0.6128\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5418 - acc: 0.7222 - val_loss: 0.7170 - val_acc: 0.6103\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.5276 - acc: 0.7309 - val_loss: 1.0153 - val_acc: 0.5320\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.5249 - acc: 0.7434 - val_loss: 0.6267 - val_acc: 0.6773\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.5165 - acc: 0.7462 - val_loss: 0.7485 - val_acc: 0.6103\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5260 - acc: 0.7497 - val_loss: 0.5825 - val_acc: 0.6949\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5227 - acc: 0.7416 - val_loss: 0.7825 - val_acc: 0.5771\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.5176 - acc: 0.7462 - val_loss: 0.8521 - val_acc: 0.5520\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5130 - acc: 0.7534 - val_loss: 0.6571 - val_acc: 0.6579\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5203 - acc: 0.7378 - val_loss: 0.6633 - val_acc: 0.6460\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.5148 - acc: 0.7562 - val_loss: 0.7450 - val_acc: 0.5971\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.4956 - acc: 0.7581 - val_loss: 1.1744 - val_acc: 0.4762\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.5016 - acc: 0.7631 - val_loss: 0.7669 - val_acc: 0.6137\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.5009 - acc: 0.7531 - val_loss: 1.1362 - val_acc: 0.5069\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4834 - acc: 0.7534 - val_loss: 0.6469 - val_acc: 0.6635\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 573s 6s/step - loss: 0.4941 - acc: 0.7675 - val_loss: 0.7387 - val_acc: 0.6190\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.4837 - acc: 0.7688 - val_loss: 0.7209 - val_acc: 0.6203\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4838 - acc: 0.7762 - val_loss: 0.5658 - val_acc: 0.7112\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 573s 6s/step - loss: 0.4862 - acc: 0.7628 - val_loss: 0.7919 - val_acc: 0.6071\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4892 - acc: 0.7609 - val_loss: 0.6533 - val_acc: 0.6579\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.4830 - acc: 0.7697 - val_loss: 0.7916 - val_acc: 0.6134\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4812 - acc: 0.7666 - val_loss: 0.6830 - val_acc: 0.6617\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.4699 - acc: 0.7706 - val_loss: 1.2188 - val_acc: 0.4706\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 577s 6s/step - loss: 0.4858 - acc: 0.7634 - val_loss: 0.6570 - val_acc: 0.6836\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.4721 - acc: 0.7784 - val_loss: 0.6435 - val_acc: 0.6761\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.4790 - acc: 0.7765 - val_loss: 0.8955 - val_acc: 0.5840\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4814 - acc: 0.7700 - val_loss: 1.0652 - val_acc: 0.5320\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 578s 6s/step - loss: 0.4711 - acc: 0.7781 - val_loss: 0.9345 - val_acc: 0.5660\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 575s 6s/step - loss: 0.4688 - acc: 0.7844 - val_loss: 0.6699 - val_acc: 0.6629\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 576s 6s/step - loss: 0.4678 - acc: 0.7759 - val_loss: 0.5380 - val_acc: 0.7513\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.4642 - acc: 0.7834 - val_loss: 0.7294 - val_acc: 0.6447\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=50) #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize= (6,6))\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.figure(figsize= (6,6))\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.title('Training and validaion accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(200, 200),\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle = False,\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "\n",
    "predict = model.predict_generator(test_generator,steps = nb_samples)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

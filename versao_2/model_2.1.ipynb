{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation,Convolution2D, Dropout,Conv2D,Dense\n",
    "from keras.layers import AveragePooling2D,BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelCNN():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"elu\",\n",
    "                           name='image_array',input_shape=(150,150,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"elu\",\n",
    "                           strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"elu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(4096,activation='elu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(4096,activation='elu'))\n",
    "    model.add(layers.Dense(2,activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images('/home/jailsonpereira/PAIC_CNN/versao_1')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image,(150,150))\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    \n",
    "\n",
    "data = np.array(data,dtype='float32')/255\n",
    "labels = np.array(labels)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "labels=le.fit_transform(labels)\n",
    "labels=to_categorical(labels,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val=train_test_split(data,labels,test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intanciando arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_array (Conv2D)         (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 150, 150, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 37, 37, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 18, 18, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 9, 9, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 57,994,050\n",
      "Trainable params: 57,988,674\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.RMSprop(lr=0.01,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,minlr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,  \n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False) \n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 53s 3s/step - loss: 4.3309 - acc: 0.7075 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 51s 3s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 49s 2s/step - loss: 4.4083 - acc: 0.7250 - val_loss: 4.1818 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(datagen.flow(X_train,Y_train,batch_size=10),epochs=10,validation_data=(X_val,Y_val),\n",
    "                          verbose=1,steps_per_epoch=X_train.shape[0]/10, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import paths\n",
    "from keras import metrics\n",
    "from keras.applications.imagenet_utils import preprocess_input as preprocess_type1\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images('/home/jailsonpereira/PAIC_CNN/dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image,(224,224))\n",
    "    data.append(image)\n",
    "    \n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    \n",
    "\n",
    "data = np.array(data,dtype='float32')/255\n",
    "labels = np.array(labels)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le=LabelEncoder()\n",
    "#labels=le.fit_transform(labels)\n",
    "#labels=to_categorical(labels,num_classes=2)\n",
    "\n",
    "X   =  preprocess_type1(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_val,Y_train,Y_val=train_test_split(data,labels,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_net = keras.applications.resnet50.ResNet50(include_top=False, weights='imagenet',pooling='avg').predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 2048)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_net.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC ( ) \n",
    "results = cross_val_score(clf,X_net,labels,cv = 5,n_jobs = - 1 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7173913  0.75555556 0.79545455 0.77272727 0.75      ]\n",
      "Overall accuracy: 75.8\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(\"Overall accuracy: {:.3}\".format(np.mean(results) * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abordagem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate  = [0.01, 0.05]\n",
    "alpha = [0.5, 2, 3]\n",
    "\n",
    "neuron_out = 2\n",
    "neuron_ini = 2048\n",
    "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver = ['lbfgs','adam','sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente:  [32, 128, 192]\n"
     ]
    }
   ],
   "source": [
    "n = []\n",
    "for a in alpha:\n",
    "    n.append(int( a * np.sqrt((neuron_ini*neuron_out))))\n",
    "print(\"Quantidade de neurônios nas camadas ocultas a serem testadas respectivamente: \", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer = [(16,16),(16,14,2),(64,64),(64,64,64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict([\n",
    "                ('solver',solver),\n",
    "                ('hidden_layer_sizes', hidden_layer),\n",
    "                ('learning_rate_init', rate),\n",
    "                ('activation', activation_functions)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(MLPClassifier(), parameters, iid=True, cv = 3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/preprocessing/label.py:743: RuntimeWarning: invalid value encountered in greater\n",
      "  y = np.array(y > threshold, dtype=np.int)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/jailsonpereira/anaconda3/envs/paic2/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=None,\n",
       "       param_grid={'solver': ['lbfgs', 'adam', 'sgd'], 'hidden_layer_sizes': [(16, 16), (16, 14, 2), (64, 64), (64, 64, 64)], 'learning_rate_init': [0.01, 0.05], 'activation': ['identity', 'logistic', 'tanh', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_net,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841032</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.681614</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>69</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>0.908066</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133861</td>\n",
       "      <td>0.115111</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.728732</td>\n",
       "      <td>0.026709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221121</td>\n",
       "      <td>0.131595</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.493274</td>\n",
       "      <td>0.355434</td>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.478747</td>\n",
       "      <td>0.339632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.803209</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>79</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.928260</td>\n",
       "      <td>0.011350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027936</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.372197</td>\n",
       "      <td>0.215471</td>\n",
       "      <td>89</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.315436</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.481831</td>\n",
       "      <td>0.192533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.282148</td>\n",
       "      <td>0.181594</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.850900</td>\n",
       "      <td>0.029846</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>71</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.919463</td>\n",
       "      <td>0.923816</td>\n",
       "      <td>0.016580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.190762</td>\n",
       "      <td>0.228613</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.488789</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.480984</td>\n",
       "      <td>0.341440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.069846</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.841238</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>71</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.946309</td>\n",
       "      <td>0.912555</td>\n",
       "      <td>0.027401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.036091</td>\n",
       "      <td>0.010021</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502242</td>\n",
       "      <td>0.357187</td>\n",
       "      <td>84</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475936</td>\n",
       "      <td>0.337389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.460304</td>\n",
       "      <td>0.020318</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>identity</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.652029</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.663677</td>\n",
       "      <td>0.020132</td>\n",
       "      <td>76</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.887871</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.395883</td>\n",
       "      <td>0.207795</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.349776</td>\n",
       "      <td>0.280823</td>\n",
       "      <td>90</td>\n",
       "      <td>0.317568</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.383261</td>\n",
       "      <td>0.337483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.426842</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.715442</td>\n",
       "      <td>0.183741</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.659193</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>78</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.919463</td>\n",
       "      <td>0.914868</td>\n",
       "      <td>0.027444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.053750</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.144885</td>\n",
       "      <td>92</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085586</td>\n",
       "      <td>0.121036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.344129</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.847417</td>\n",
       "      <td>0.076621</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.031444</td>\n",
       "      <td>79</td>\n",
       "      <td>0.952703</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>0.928306</td>\n",
       "      <td>0.044573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.070110</td>\n",
       "      <td>0.010501</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502242</td>\n",
       "      <td>0.357187</td>\n",
       "      <td>84</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475936</td>\n",
       "      <td>0.337389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.250876</td>\n",
       "      <td>0.220804</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.769010</td>\n",
       "      <td>0.118339</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.024243</td>\n",
       "      <td>65</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.932886</td>\n",
       "      <td>0.905829</td>\n",
       "      <td>0.021921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269058</td>\n",
       "      <td>0.381789</td>\n",
       "      <td>91</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.322706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.847171</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.881658</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.699552</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>62</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.919463</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.892376</td>\n",
       "      <td>0.021922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.069314</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.067170</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.975872</td>\n",
       "      <td>0.044807</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.735426</td>\n",
       "      <td>0.043633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.832215</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.876806</td>\n",
       "      <td>0.041651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.051052</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>logistic</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'logistic', 'hidden_layer_sizes...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2.878133</td>\n",
       "      <td>0.047274</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.645740</td>\n",
       "      <td>0.023069</td>\n",
       "      <td>81</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.887916</td>\n",
       "      <td>0.008068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.123812</td>\n",
       "      <td>0.027265</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.431815</td>\n",
       "      <td>0.251907</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2.901702</td>\n",
       "      <td>0.110456</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.699552</td>\n",
       "      <td>0.051458</td>\n",
       "      <td>62</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.869944</td>\n",
       "      <td>0.011533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.150275</td>\n",
       "      <td>0.110099</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.138052</td>\n",
       "      <td>0.080094</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>tanh</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'tanh', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.788102</td>\n",
       "      <td>0.050308</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>65</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.838926</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.876746</td>\n",
       "      <td>0.027902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.501800</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.040680</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.029895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.339771</td>\n",
       "      <td>0.139917</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.753535</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.704036</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>58</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.883397</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.193079</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.636771</td>\n",
       "      <td>0.169973</td>\n",
       "      <td>82</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.536913</td>\n",
       "      <td>0.654907</td>\n",
       "      <td>0.086805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.044655</td>\n",
       "      <td>0.011266</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 16)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.457399</td>\n",
       "      <td>0.322424</td>\n",
       "      <td>88</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.498307</td>\n",
       "      <td>0.352373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.704036</td>\n",
       "      <td>0.077868</td>\n",
       "      <td>58</td>\n",
       "      <td>0.817568</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.751270</td>\n",
       "      <td>0.054299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.595810</td>\n",
       "      <td>0.243359</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.717489</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>52</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.722021</td>\n",
       "      <td>0.026564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.213008</td>\n",
       "      <td>0.016484</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.513168</td>\n",
       "      <td>0.322644</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.050865</td>\n",
       "      <td>71</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.825503</td>\n",
       "      <td>0.785235</td>\n",
       "      <td>0.784660</td>\n",
       "      <td>0.033585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.102459</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.070622</td>\n",
       "      <td>0.004217</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>relu</td>\n",
       "      <td>(16, 14, 2)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2.556981</td>\n",
       "      <td>0.259144</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.713004</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>56</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.859060</td>\n",
       "      <td>0.849764</td>\n",
       "      <td>0.006587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.955953</td>\n",
       "      <td>0.105156</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>71</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.764617</td>\n",
       "      <td>0.013827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.289767</td>\n",
       "      <td>0.035716</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.829550</td>\n",
       "      <td>0.808839</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.717489</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>52</td>\n",
       "      <td>0.858108</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.845638</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.053801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.158832</td>\n",
       "      <td>0.053405</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.587444</td>\n",
       "      <td>0.225676</td>\n",
       "      <td>83</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.607126</td>\n",
       "      <td>0.159344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.268301</td>\n",
       "      <td>0.034027</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.423966</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.721973</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>50</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.802769</td>\n",
       "      <td>0.036954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.609413</td>\n",
       "      <td>0.117326</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.699552</td>\n",
       "      <td>0.033322</td>\n",
       "      <td>62</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.791946</td>\n",
       "      <td>0.764541</td>\n",
       "      <td>0.019390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.383753</td>\n",
       "      <td>0.153302</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2.548884</td>\n",
       "      <td>0.080051</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>65</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.852349</td>\n",
       "      <td>0.818792</td>\n",
       "      <td>0.838579</td>\n",
       "      <td>0.014345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.145511</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.156166</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>relu</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.05</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'activation': 'relu', 'hidden_layer_sizes': (...</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>4</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.751678</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.029849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.841032      0.041939         0.001417        0.000015   \n",
       "1        0.133861      0.115111         0.001406        0.000012   \n",
       "2        0.221121      0.131595         0.001374        0.000021   \n",
       "3        0.803209      0.007865         0.001420        0.000016   \n",
       "4        0.027936      0.000150         0.001425        0.000009   \n",
       "5        0.282148      0.181594         0.001510        0.000025   \n",
       "6        0.850900      0.029846         0.001436        0.000038   \n",
       "7        0.190762      0.228613         0.001474        0.000008   \n",
       "8        0.069846      0.011669         0.001412        0.000004   \n",
       "9        0.841238      0.034213         0.001766        0.000452   \n",
       "10       0.036091      0.010021         0.001447        0.000047   \n",
       "11       0.460304      0.020318         0.001665        0.000218   \n",
       "12       2.652029      0.178947         0.001608        0.000026   \n",
       "13       0.395883      0.207795         0.001688        0.000100   \n",
       "14       0.426842      0.104094         0.001668        0.000064   \n",
       "15       2.715442      0.183741         0.001769        0.000243   \n",
       "16       0.053750      0.000226         0.001715        0.000041   \n",
       "17       0.539779      0.344129         0.001742        0.000095   \n",
       "18       2.847417      0.076621         0.001888        0.000273   \n",
       "19       0.070110      0.010501         0.001783        0.000037   \n",
       "20       0.250876      0.220804         0.001770        0.000046   \n",
       "21       2.769010      0.118339         0.001618        0.000055   \n",
       "22       0.064924      0.001095         0.001787        0.000081   \n",
       "23       0.847171      0.009253         0.001681        0.000060   \n",
       "24       0.881658      0.009538         0.002010        0.000744   \n",
       "25       0.069314      0.008387         0.001471        0.000033   \n",
       "26       0.067170      0.012487         0.001689        0.000286   \n",
       "27       0.975872      0.044807         0.001460        0.000015   \n",
       "28       0.085308      0.027535         0.002077        0.000865   \n",
       "29       0.051052      0.008512         0.001468        0.000030   \n",
       "..            ...           ...              ...             ...   \n",
       "66       2.878133      0.047274         0.001817        0.000010   \n",
       "67       0.123812      0.027265         0.002002        0.000093   \n",
       "68       0.431815      0.251907         0.002013        0.000149   \n",
       "69       2.901702      0.110456         0.001904        0.000095   \n",
       "70       0.150275      0.110099         0.001897        0.000106   \n",
       "71       0.138052      0.080094         0.001910        0.000085   \n",
       "72       0.788102      0.050308         0.001440        0.000007   \n",
       "73       0.501800      0.057807         0.001421        0.000012   \n",
       "74       0.339771      0.139917         0.001415        0.000014   \n",
       "75       0.753535      0.021603         0.001430        0.000007   \n",
       "76       0.193079      0.030466         0.001422        0.000006   \n",
       "77       0.044655      0.011266         0.001413        0.000028   \n",
       "78       0.263300      0.326000         0.001444        0.000005   \n",
       "79       0.595810      0.243359         0.001439        0.000004   \n",
       "80       0.213008      0.016484         0.001734        0.000410   \n",
       "81       0.513168      0.322644         0.001487        0.000049   \n",
       "82       0.102459      0.037505         0.001437        0.000009   \n",
       "83       0.070622      0.004217         0.001450        0.000025   \n",
       "84       2.556981      0.259144         0.001726        0.000054   \n",
       "85       0.955953      0.105156         0.002917        0.001802   \n",
       "86       0.289767      0.035716         0.001595        0.000110   \n",
       "87       1.829550      0.808839         0.001683        0.000025   \n",
       "88       0.158832      0.053405         0.001638        0.000097   \n",
       "89       0.268301      0.034027         0.001530        0.000013   \n",
       "90       2.423966      0.094026         0.001608        0.000085   \n",
       "91       0.609413      0.117326         0.001665        0.000116   \n",
       "92       0.383753      0.153302         0.001632        0.000090   \n",
       "93       2.548884      0.080051         0.001552        0.000016   \n",
       "94       0.191964      0.145511         0.001623        0.000034   \n",
       "95       0.156166      0.070757         0.001724        0.000096   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "0          identity                 (16, 16)                     0.01   \n",
       "1          identity                 (16, 16)                     0.01   \n",
       "2          identity                 (16, 16)                     0.01   \n",
       "3          identity                 (16, 16)                     0.05   \n",
       "4          identity                 (16, 16)                     0.05   \n",
       "5          identity                 (16, 16)                     0.05   \n",
       "6          identity              (16, 14, 2)                     0.01   \n",
       "7          identity              (16, 14, 2)                     0.01   \n",
       "8          identity              (16, 14, 2)                     0.01   \n",
       "9          identity              (16, 14, 2)                     0.05   \n",
       "10         identity              (16, 14, 2)                     0.05   \n",
       "11         identity              (16, 14, 2)                     0.05   \n",
       "12         identity                 (64, 64)                     0.01   \n",
       "13         identity                 (64, 64)                     0.01   \n",
       "14         identity                 (64, 64)                     0.01   \n",
       "15         identity                 (64, 64)                     0.05   \n",
       "16         identity                 (64, 64)                     0.05   \n",
       "17         identity                 (64, 64)                     0.05   \n",
       "18         identity             (64, 64, 64)                     0.01   \n",
       "19         identity             (64, 64, 64)                     0.01   \n",
       "20         identity             (64, 64, 64)                     0.01   \n",
       "21         identity             (64, 64, 64)                     0.05   \n",
       "22         identity             (64, 64, 64)                     0.05   \n",
       "23         identity             (64, 64, 64)                     0.05   \n",
       "24         logistic                 (16, 16)                     0.01   \n",
       "25         logistic                 (16, 16)                     0.01   \n",
       "26         logistic                 (16, 16)                     0.01   \n",
       "27         logistic                 (16, 16)                     0.05   \n",
       "28         logistic                 (16, 16)                     0.05   \n",
       "29         logistic                 (16, 16)                     0.05   \n",
       "..              ...                      ...                      ...   \n",
       "66             tanh             (64, 64, 64)                     0.01   \n",
       "67             tanh             (64, 64, 64)                     0.01   \n",
       "68             tanh             (64, 64, 64)                     0.01   \n",
       "69             tanh             (64, 64, 64)                     0.05   \n",
       "70             tanh             (64, 64, 64)                     0.05   \n",
       "71             tanh             (64, 64, 64)                     0.05   \n",
       "72             relu                 (16, 16)                     0.01   \n",
       "73             relu                 (16, 16)                     0.01   \n",
       "74             relu                 (16, 16)                     0.01   \n",
       "75             relu                 (16, 16)                     0.05   \n",
       "76             relu                 (16, 16)                     0.05   \n",
       "77             relu                 (16, 16)                     0.05   \n",
       "78             relu              (16, 14, 2)                     0.01   \n",
       "79             relu              (16, 14, 2)                     0.01   \n",
       "80             relu              (16, 14, 2)                     0.01   \n",
       "81             relu              (16, 14, 2)                     0.05   \n",
       "82             relu              (16, 14, 2)                     0.05   \n",
       "83             relu              (16, 14, 2)                     0.05   \n",
       "84             relu                 (64, 64)                     0.01   \n",
       "85             relu                 (64, 64)                     0.01   \n",
       "86             relu                 (64, 64)                     0.01   \n",
       "87             relu                 (64, 64)                     0.05   \n",
       "88             relu                 (64, 64)                     0.05   \n",
       "89             relu                 (64, 64)                     0.05   \n",
       "90             relu             (64, 64, 64)                     0.01   \n",
       "91             relu             (64, 64, 64)                     0.01   \n",
       "92             relu             (64, 64, 64)                     0.01   \n",
       "93             relu             (64, 64, 64)                     0.05   \n",
       "94             relu             (64, 64, 64)                     0.05   \n",
       "95             relu             (64, 64, 64)                     0.05   \n",
       "\n",
       "   param_solver                                             params  \\\n",
       "0         lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "1          adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "2           sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "3         lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "4          adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "5           sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "6         lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "7          adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "8           sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "9         lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "10         adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "11          sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "12        lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "13         adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "14          sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "15        lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "16         adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "17          sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "18        lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "19         adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "20          sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "21        lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "22         adam  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "23          sgd  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "24        lbfgs  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "25         adam  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "26          sgd  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "27        lbfgs  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "28         adam  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "29          sgd  {'activation': 'logistic', 'hidden_layer_sizes...   \n",
       "..          ...                                                ...   \n",
       "66        lbfgs  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "67         adam  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "68          sgd  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "69        lbfgs  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "70         adam  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "71          sgd  {'activation': 'tanh', 'hidden_layer_sizes': (...   \n",
       "72        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "73         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "74          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "75        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "76         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "77          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "78        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "79         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "80          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "81        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "82         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "83          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "84        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "85         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "86          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "87        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "88         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "89          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "90        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "91         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "92          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "93        lbfgs  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "94         adam  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "95          sgd  {'activation': 'relu', 'hidden_layer_sizes': (...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.680000           0.716216           0.648649         0.681614   \n",
       "1            0.693333           0.810811           0.675676         0.726457   \n",
       "2            0.000000           0.810811           0.675676         0.493274   \n",
       "3            0.640000           0.702703           0.621622         0.654709   \n",
       "4            0.253333           0.189189           0.675676         0.372197   \n",
       "5            0.000000           0.000000           0.000000         0.000000   \n",
       "6            0.666667           0.716216           0.648649         0.677130   \n",
       "7            0.000000           0.810811           0.662162         0.488789   \n",
       "8            0.693333           0.810811           0.675676         0.726457   \n",
       "9            0.666667           0.689189           0.675676         0.677130   \n",
       "10           0.693333           0.810811           0.000000         0.502242   \n",
       "11           0.000000           0.000000           0.000000         0.000000   \n",
       "12           0.640000           0.662162           0.689189         0.663677   \n",
       "13           0.360000           0.000000           0.689189         0.349776   \n",
       "14           0.693333           0.810811           0.675676         0.726457   \n",
       "15           0.613333           0.689189           0.675676         0.659193   \n",
       "16           0.306667           0.000000           0.000000         0.103139   \n",
       "17           0.000000           0.000000           0.000000         0.000000   \n",
       "18           0.613333           0.689189           0.662162         0.654709   \n",
       "19           0.693333           0.810811           0.000000         0.502242   \n",
       "20           0.693333           0.810811           0.675676         0.726457   \n",
       "21           0.720000           0.702703           0.662162         0.695067   \n",
       "22           0.000000           0.810811           0.000000         0.269058   \n",
       "23           0.000000           0.000000           0.000000         0.000000   \n",
       "24           0.706667           0.635135           0.756757         0.699552   \n",
       "25           0.693333           0.810811           0.675676         0.726457   \n",
       "26           0.693333           0.810811           0.675676         0.726457   \n",
       "27           0.706667           0.797297           0.702703         0.735426   \n",
       "28           0.693333           0.810811           0.675676         0.726457   \n",
       "29           0.693333           0.810811           0.675676         0.726457   \n",
       "..                ...                ...                ...              ...   \n",
       "66           0.613333           0.662162           0.662162         0.645740   \n",
       "67           0.693333           0.810811           0.675676         0.726457   \n",
       "68           0.693333           0.810811           0.675676         0.726457   \n",
       "69           0.680000           0.770270           0.648649         0.699552   \n",
       "70           0.693333           0.810811           0.675676         0.726457   \n",
       "71           0.693333           0.810811           0.675676         0.726457   \n",
       "72           0.680000           0.743243           0.662162         0.695067   \n",
       "73           0.720000           0.810811           0.729730         0.753363   \n",
       "74           0.693333           0.810811           0.675676         0.726457   \n",
       "75           0.720000           0.689189           0.702703         0.704036   \n",
       "76           0.693333           0.810811           0.405405         0.636771   \n",
       "77           0.693333           0.000000           0.675676         0.457399   \n",
       "78           0.626667           0.810811           0.675676         0.704036   \n",
       "79           0.693333           0.810811           0.648649         0.717489   \n",
       "80           0.693333           0.810811           0.675676         0.726457   \n",
       "81           0.693333           0.729730           0.608108         0.677130   \n",
       "82           0.693333           0.810811           0.675676         0.726457   \n",
       "83           0.693333           0.810811           0.675676         0.726457   \n",
       "84           0.733333           0.729730           0.675676         0.713004   \n",
       "85           0.653333           0.702703           0.675676         0.677130   \n",
       "86           0.693333           0.810811           0.675676         0.726457   \n",
       "87           0.733333           0.756757           0.662162         0.717489   \n",
       "88           0.280000           0.810811           0.675676         0.587444   \n",
       "89           0.693333           0.810811           0.675676         0.726457   \n",
       "90           0.733333           0.743243           0.689189         0.721973   \n",
       "91           0.693333           0.743243           0.662162         0.699552   \n",
       "92           0.693333           0.810811           0.675676         0.726457   \n",
       "93           0.693333           0.689189           0.702703         0.695067   \n",
       "94           0.693333           0.810811           0.675676         0.726457   \n",
       "95           0.693333           0.810811           0.675676         0.726457   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.027546               69            0.905405            0.906040   \n",
       "1         0.059883                4            0.743243            0.691275   \n",
       "2         0.355434               86            0.000000            0.684564   \n",
       "3         0.034647               79            0.932432            0.912752   \n",
       "4         0.215471               89            0.378378            0.315436   \n",
       "5         0.000000               93            0.000000            0.000000   \n",
       "6         0.028513               71            0.945946            0.906040   \n",
       "7         0.353183               87            0.000000            0.684564   \n",
       "8         0.059883                4            0.743243            0.684564   \n",
       "9         0.009262               71            0.912162            0.879195   \n",
       "10        0.357187               84            0.743243            0.684564   \n",
       "11        0.000000               93            0.000000            0.000000   \n",
       "12        0.020132               76            0.878378            0.892617   \n",
       "13        0.280823               90            0.317568            0.006711   \n",
       "14        0.059883                4            0.743243            0.684564   \n",
       "15        0.033107               78            0.945946            0.879195   \n",
       "16        0.144885               92            0.256757            0.000000   \n",
       "17        0.000000               93            0.000000            0.000000   \n",
       "18        0.031444               79            0.952703            0.865772   \n",
       "19        0.357187               84            0.743243            0.684564   \n",
       "20        0.059883                4            0.743243            0.684564   \n",
       "21        0.024243               65            0.905405            0.879195   \n",
       "22        0.381789               91            0.000000            0.684564   \n",
       "23        0.000000               93            0.000000            0.000000   \n",
       "24        0.049799               62            0.891892            0.919463   \n",
       "25        0.059883                4            0.743243            0.684564   \n",
       "26        0.059883                4            0.743243            0.684564   \n",
       "27        0.043633                3            0.932432            0.832215   \n",
       "28        0.059883                4            0.743243            0.684564   \n",
       "29        0.059883                4            0.743243            0.684564   \n",
       "..             ...              ...                 ...                 ...   \n",
       "66        0.023069               81            0.898649            0.879195   \n",
       "67        0.059883                4            0.743243            0.684564   \n",
       "68        0.059883                4            0.743243            0.684564   \n",
       "69        0.051458               62            0.864865            0.859060   \n",
       "70        0.059883                4            0.743243            0.684564   \n",
       "71        0.059883                4            0.743243            0.684564   \n",
       "72        0.034725               65            0.905405            0.838926   \n",
       "73        0.040680                1            0.898649            0.825503   \n",
       "74        0.059883                4            0.743243            0.684564   \n",
       "75        0.012627               58            0.878378            0.885906   \n",
       "76        0.169973               82            0.743243            0.684564   \n",
       "77        0.322424               88            0.743243            0.000000   \n",
       "78        0.077868               58            0.817568            0.684564   \n",
       "79        0.068255               52            0.743243            0.684564   \n",
       "80        0.059883                4            0.743243            0.684564   \n",
       "81        0.050865               71            0.743243            0.825503   \n",
       "82        0.059883                4            0.743243            0.684564   \n",
       "83        0.059883                4            0.743243            0.684564   \n",
       "84        0.026348               56            0.844595            0.845638   \n",
       "85        0.020203               71            0.783784            0.758389   \n",
       "86        0.059883                4            0.743243            0.684564   \n",
       "87        0.040148               52            0.858108            0.738255   \n",
       "88        0.225676               83            0.385135            0.684564   \n",
       "89        0.059883                4            0.743243            0.684564   \n",
       "90        0.023456               50            0.837838            0.751678   \n",
       "91        0.033322               62            0.750000            0.751678   \n",
       "92        0.059883                4            0.743243            0.684564   \n",
       "93        0.005641               65            0.844595            0.852349   \n",
       "94        0.059883                4            0.743243            0.684564   \n",
       "95        0.059883                4            0.743243            0.684564   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.912752          0.908066         0.003324  \n",
       "1             0.751678          0.728732         0.026709  \n",
       "2             0.751678          0.478747         0.339632  \n",
       "3             0.939597          0.928260         0.011350  \n",
       "4             0.751678          0.481831         0.192533  \n",
       "5             0.000000          0.000000         0.000000  \n",
       "6             0.919463          0.923816         0.016580  \n",
       "7             0.758389          0.480984         0.341440  \n",
       "8             0.751678          0.726495         0.029849  \n",
       "9             0.946309          0.912555         0.027401  \n",
       "10            0.000000          0.475936         0.337389  \n",
       "11            0.000000          0.000000         0.000000  \n",
       "12            0.892617          0.887871         0.006712  \n",
       "13            0.825503          0.383261         0.337483  \n",
       "14            0.751678          0.726495         0.029849  \n",
       "15            0.919463          0.914868         0.027444  \n",
       "16            0.000000          0.085586         0.121036  \n",
       "17            0.000000          0.000000         0.000000  \n",
       "18            0.966443          0.928306         0.044573  \n",
       "19            0.000000          0.475936         0.337389  \n",
       "20            0.751678          0.726495         0.029849  \n",
       "21            0.932886          0.905829         0.021921  \n",
       "22            0.000000          0.228188         0.322706  \n",
       "23            0.000000          0.000000         0.000000  \n",
       "24            0.865772          0.892376         0.021922  \n",
       "25            0.751678          0.726495         0.029849  \n",
       "26            0.751678          0.726495         0.029849  \n",
       "27            0.865772          0.876806         0.041651  \n",
       "28            0.751678          0.726495         0.029849  \n",
       "29            0.751678          0.726495         0.029849  \n",
       "..                 ...               ...              ...  \n",
       "66            0.885906          0.887916         0.008068  \n",
       "67            0.751678          0.726495         0.029849  \n",
       "68            0.751678          0.726495         0.029849  \n",
       "69            0.885906          0.869944         0.011533  \n",
       "70            0.751678          0.726495         0.029849  \n",
       "71            0.751678          0.726495         0.029849  \n",
       "72            0.885906          0.876746         0.027902  \n",
       "73            0.859060          0.861071         0.029895  \n",
       "74            0.751678          0.726495         0.029849  \n",
       "75            0.885906          0.883397         0.003549  \n",
       "76            0.536913          0.654907         0.086805  \n",
       "77            0.751678          0.498307         0.352373  \n",
       "78            0.751678          0.751270         0.054299  \n",
       "79            0.738255          0.722021         0.026564  \n",
       "80            0.751678          0.726495         0.029849  \n",
       "81            0.785235          0.784660         0.033585  \n",
       "82            0.751678          0.726495         0.029849  \n",
       "83            0.751678          0.726495         0.029849  \n",
       "84            0.859060          0.849764         0.006587  \n",
       "85            0.751678          0.764617         0.013827  \n",
       "86            0.751678          0.726495         0.029849  \n",
       "87            0.845638          0.814000         0.053801  \n",
       "88            0.751678          0.607126         0.159344  \n",
       "89            0.751678          0.726495         0.029849  \n",
       "90            0.818792          0.802769         0.036954  \n",
       "91            0.791946          0.764541         0.019390  \n",
       "92            0.751678          0.726495         0.029849  \n",
       "93            0.818792          0.838579         0.014345  \n",
       "94            0.751678          0.726495         0.029849  \n",
       "95            0.751678          0.726495         0.029849  \n",
       "\n",
       "[96 rows x 20 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "resultado = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor média de acurácia entre os folds = 0.9283058226011246\n"
     ]
    }
   ],
   "source": [
    "print(\"Melhor média de acurácia entre os folds = \" + str(max(resultado['mean_train_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_activation</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.847417</td>\n",
       "      <td>0.076621</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>identity</td>\n",
       "      <td>(64, 64, 64)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'activation': 'identity', 'hidden_layer_sizes...</td>\n",
       "      <td>0.613333</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.654709</td>\n",
       "      <td>0.031444</td>\n",
       "      <td>79</td>\n",
       "      <td>0.952703</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>0.928306</td>\n",
       "      <td>0.044573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18       2.847417      0.076621         0.001888        0.000273   \n",
       "\n",
       "   param_activation param_hidden_layer_sizes param_learning_rate_init  \\\n",
       "18         identity             (64, 64, 64)                     0.01   \n",
       "\n",
       "   param_solver                                             params  \\\n",
       "18        lbfgs  {'activation': 'identity', 'hidden_layer_sizes...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "18           0.613333           0.689189           0.662162         0.654709   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "18        0.031444               79            0.952703            0.865772   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "18            0.966443          0.928306         0.044573  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.loc[resultado['mean_train_score']==max(resultado['mean_train_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

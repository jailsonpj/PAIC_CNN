{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É um método de otimização usado na aprendizagem de máquina. Se tratando de uma simples regressão linear, o gradiente descendente só é recomendado quando temos dados com muitas dimensões. Nesse caso, a inversão da matriz X^t X comeca a demorar muito a resolver a regressão linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas convexos têm apenas um mínimo; ou seja, apenas um lugar onde a inclinação é exatamente 0. Esse mínimo é onde a função de perda converge.\n",
    "\n",
    "Calculando a função de perda para cada valor concebível ao longo de todo o conjunto de dados seria uma maneira ineficiente de encontrar o ponto de convergência. Existe uma maneira de examinar esse mecanismo melhor chamado gradiente de descida.\n",
    "\n",
    "O primeiro estágio no gradiente de descida é escolher um valor inicial (um ponto inicial). O ponto de partida não importa muito; Portanto, muitos algoritmos simplesmente definem w1 a 0 ou selecionam um valor aleatório.\n",
    "\n",
    "O algoritmo de gradiente descendente calcula então o gradiente da curva de perda no ponto inicial. Na figura, o gradiente de perda é igual a derivada(inclinação) da curva, e indica qual é caminho mais \"quente\" ou \"mais frio\". Quando há vários pesos, o gradiente é um vetor de derivadas parciais com relação aos pesos.\n",
    "\n",
    "O gradiente sempre aponta na direção do aumento mais acentuado na função de perda. O algoritmo de descida de gradiente dá um passo na direção do gradiente negativo para reduzir a perda o mais rápido possível.\n",
    "\n",
    "\"A descida de gradiente depende de gradientes negativos\"\n",
    "\n",
    "Para detrminar o próximo ponto ao longo da curva da função de perda, o algoritmo de descida de gradiente adiciona alguma fração da magnitude do gradiente ao ponto de partida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduzindo Perdas: Taxa de Aprendizagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observado, o vetor gradiente tem uma direção e uma magnitude. Os algoritmos de descida de gradiente multiplicam o gradiente por um escalar conhecido como Taxa de aprendizado (tbm chamado de tamanho de etapa) para determinar o próximo ponto. Por exemplo, se a magnitude do gradiente for 2,5 e ataxa de aprendizado for 0,01 , o algoritmo de descida de gradiente escolherá o próximo ponto 0,025 do ponto anterior.\n",
    "\n",
    "Os Hiperparâmetros são os botões que os programadores ajustam nos algoritmos de aprendizado de máquina. A maioria dos programadores de aprendizado de máquina gasta um tempo ajustando a taxa de aprendizado. Se caso a taxa de aprendizado for muito pequena, o aprendizado demorará demais. Por outro lado, se a taxa de aprendizado for muito grande, o próximo ponto irá perpentuamente saltar aleatoriamente pela parte parte inferior do poço, como um experimento de macânica quântica que deu terrivelmente errado.\n",
    "\n",
    "Há uma taxa de aprendizado de Goldilocks[ https://en.wikipedia.org/wiki/Goldilocks_principle ] para cada problema de regressão. O valor de cachinhos Dourados está relacionado a quão plana é a função de perda. Se você sabe que o gradiente da função de perda é pequeno, então você pode tentar com segurança uma taxa de aprendizado maior, que compensa o pequeno gradiente e resulta em um tamanho de etapa maior.\n",
    "\n",
    "1/f(x)^n , taxa de apredizado ideal para 2 ou mais dimensões. É o inverso da Hessiana(matriz da segundas derivadsa parciais).\n",
    "\n",
    "A taxa de aprendizado não deve ser nem tão grande, nem tão pequena. Uma sugestão de ajustamento desse hiper-parâmetro é começar com 0.01 e explorar os pontos em volta dez vezes maior/menor (isto é, 0.1 e 0.001). Na maioria dos casos, uma boa taxa de aprendizado será algum dos seguintes valores: 1, 0.1, 0.01, 0.001, 0.0001, 0.00001.\n",
    "\n",
    "Com uma boa taxa de aprendizado, selecionar o número de iterações de treino é uma tarefa fácil. Mesmo assim, recomenda-se plotar o valor da função custo a cada iteração de treino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perda Reduzindo: Descida Estocástica de Gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gradiente descendente, um \"Lote\" é número total de exemplos que você usa para calcular o gradiente em uma única iteração. Um lote pode ser enorme. Um lote muito grande pode fazer com que até mesmo uma única iteração demore muito tempo para ser computada.\n",
    "\n",
    "Um grande conjunto de dados com exemplos amostrados aleatoriamente provavelmente contém dados redundantes. Na verdade, a redundância se torna mais provável à medida que o tamanho do lote aumenta. Alguma redundância pode ser útil para suavizar gradientes ruidosos, mas lotes enormes tendem a não ter muito mais valor preditivo do que grandes lotes.\n",
    "\n",
    "E se pudéssemos obter o gradiente correto em média para muito menos computação? AO escolher exemplos aleatoriaemnte de nosso conjunto de dados, poderíamos estimar (embora com muito ruído) uma grande média de um muito menor. A descida de gradiente estocástica (SGD) leva essa idéia ao extremo - ela usa apenas um único exemplo (um tamanho de lote de 1) por iteração. Dado iterações suficientes, o SGD funciona, mas é muito barulhento. O termo \"estocástico\" indica que o exemplo que compreende cada lote é escolhido aleatoriamente.\n",
    "\n",
    "Descendência de gradiente estocástica em mini-lote (mini-lote SGD) é um  compromisso entre a iteração completa e o SGD. Um mini-lote é tipicamente entre 10 a 1.000 exemplos, escolhidos aleatoriamente. O mini-lote SGD reduz a quantidade de ruído no SGD, mas ainda é mais eficiente que o full-batch\n",
    "\n",
    "O GDE normalmente não converge, mas fica vagando em alguma região próxima ao ponto de mínimo. Na prática, isso não é um problema, pois nessa região o custo já é baixo o suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando e Visualizando o Gradiente Descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendo uma função y = 5 + 3x + e , em que e é algum erro aleatório.\n",
    "\n",
    "Como a cada iteração os parâmetros b e w dão um passo em direção ao mínimo. O taamanho desse passo será o valor do gradiente naquele ponto multiplicado pela constante a.\n",
    "\n",
    "Quanto mais próximo estamos do ponto de mínimo, menor a inclinação da função custo, ou seja menor o gradiente, ou seja, menor o passo dado em direção ao mínimo.\n",
    "\n",
    "Essa característica do método de gradiente descendente é ao mesmo tempo boa e ruim. É ruim pois atrasa o processo de aprendizado quando chegamos próximo do mínimo, mas é boa porque nos permite uma exploração mais minunciosa da superfície de custo em torno do ponto de mínimo. Dessa forma, podemos localizá-lo com mais precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear com Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) #para consistencia nos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.DataFrame()\n",
    "dados['x'] = np.linspace(-10,10,100)\n",
    "dados['y'] = 5 + 3*dados['x'] + np.random.normal(0,3,100)\n",
    "\n",
    "#define a função custo\n",
    "def L(y,y_hat):\n",
    "    return ((y-y_hat)**2).sum()\n",
    "\n",
    "#implementa regressão linear com gradiente descendente\n",
    "class linear_regr(object):\n",
    "    \n",
    "    def __init__(self, learning_rate=0.0001, training_iters=50):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_iters = training_iters\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        # formata os dados\n",
    "        if len(X_train.values.shape) < 2:\n",
    "            X = X_train.values.reshape(-1,1)\n",
    "        X = np.insert(X,0,1,1)\n",
    "        \n",
    "        #inicia os parâmetros com pequenos valores aleatórios\n",
    "        # (nosso chute razoável)\n",
    "        self.w_hat = np.random.normal(0,5,size = X[0].shape)\n",
    "        \n",
    "        for _ in range(self.training_iters):\n",
    "            gradiente = np.zeros(self.w_hat.shape) #inicia o gradiente\n",
    "            \n",
    "            #computa o gradiente com informação de todos os pontos\n",
    "            for point, yi in zip(X,y_train):\n",
    "                gradiente += (point * self.w_hat - yi) * point\n",
    "                \n",
    "            #multiplica o gradinte pela taxa de aprendizado\n",
    "            gradiente *= self.learning_rate\n",
    "            \n",
    "            #atualiza os parâmetros\n",
    "            self.w_hat -= gradiente\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        #formata os dados\n",
    "        if len(X_test.values.shape) < 2:\n",
    "            X = X_test.values.reshape(-1,1)\n",
    "        X = np.insert(X,0,1,1)\n",
    "        \n",
    "        return np.dot(X, self.w_hat)\n",
    "    \n",
    "regr = linear_regr(learning_rate=0.0005, training_iters=30)\n",
    "regr.fit(dados['x'],dados['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear com GDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "\n",
    "class linear_regr1(object):\n",
    "\n",
    "    def __init__(self, learning_rate=0.0001, training_iters=30, batch_size=10, show_learning=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_iters = training_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.show_learning = show_learning\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train, plot=False):\n",
    "        \n",
    "        # formata os dados\n",
    "        if len(X_train.values.shape) < 2:\n",
    "            X = X_train.values.reshape(-1,1)\n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "        # para plotar o aprendizado (é preciso conhecer a equação geradora)\n",
    "        if self.show_learning:\n",
    "            assert X.shape[1] <= 2 # só é possível viazualizar 2 parâmetros\n",
    "            self.w1_loss = [L(y_train, 5 + i * X_train) for i in np.linspace(0,6,20)]\n",
    "            self.b_loss = [L(y_train, i + 3 * X_train) for i in np.linspace(-10,20,20)]\n",
    "        \n",
    "        # inicia os parâmetros com pequenos valores aleatórios (nosso chute razoável)\n",
    "        self.w_hat = np.random.normal(0,5, size = X[0].shape)\n",
    "        \n",
    "        loss = [] # para plotar o aprendizado\n",
    "        for i in range(self.training_iters):\n",
    "            \n",
    "            # cria os mini-lotes\n",
    "            offset = (i * self.batch_size) % (y_train.shape[0] - self.batch_size)\n",
    "            batch_X = X[offset:(offset + self.batch_size), :]\n",
    "            batch_y = y_train[offset:(offset + self.batch_size)]\n",
    "            \n",
    "            gradient = np.zeros(self.w_hat.shape) # inicia o gradiente\n",
    "            \n",
    "            # atualiza o gradiente com informação dos pontos do lote\n",
    "            for point, yi in zip(batch_X, batch_y):\n",
    "                gradient +=  (point * self.w_hat - yi) * point\n",
    "            \n",
    "            gradient *= self.learning_rate # multiplica o gradiente pela taxa de aprendizado\n",
    "            \n",
    "            \n",
    "            # atualiza os parâmetros\n",
    "            self.w_hat -= gradient\n",
    "            \n",
    "            l = ((y_train - self.predict(X_train)) ** 2).sum() # calcula o custo\n",
    "                        \n",
    "            loss.append(l) # armazeno o custo para gráfico\n",
    "        \n",
    "            if self.show_learning:\n",
    "                # mostra o estado atual do aprendizado\n",
    "                self._show_state(X_train, y_train, loss) \n",
    "            \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        # formata os dados\n",
    "        if len(X_test.values.shape) < 2:\n",
    "            X = X_test.values.reshape(-1,1)\n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "        return np.dot(X, self.w_hat) \n",
    "    \n",
    "    \n",
    "    def _show_state(self, X_train, y_train, loss):\n",
    "        # visualiza o processo de aprendizado\n",
    "        lb = L(y_train, self.w_hat[0] + 3 * X_train) # calcula o custo na direção b\n",
    "        lw = L(y_train, 5 + self.w_hat[1] * X_train) # calcula o custo na direção w\n",
    "\n",
    "        # scatter plot\n",
    "        plt.subplot(221)\n",
    "        plt.scatter(X_train, y_train, s= 10)\n",
    "        plt.plot(X_train, self.predict(X_train), c='r')\n",
    "        plt.title('$y = b + w x$')\n",
    "        plt.tick_params(labelsize=9, labelleft=False, labelbottom = False)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # loss\n",
    "        plt.subplot(222)\n",
    "        plt.plot(range(len(loss)), loss)\n",
    "        plt.title('Custo')\n",
    "        plt.tick_params(labelsize=9, labelleft=False, labelbottom = False)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # b_loss\n",
    "        plt.subplot(223)\n",
    "        plt.plot( np.linspace(-10,20,20), self.b_loss)\n",
    "        plt.scatter(self.w_hat[0], lb, c = 'k')\n",
    "        plt.title('Custo em $\\hat{b}$')\n",
    "        plt.tick_params(labelleft=False)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # w_loss\n",
    "        plt.subplot(224)\n",
    "        plt.plot(np.linspace(0,6,20), self.w1_loss)\n",
    "        plt.scatter(self.w_hat[1], lw, c = 'k')\n",
    "        plt.title('Custo em $\\hat{w}$')\n",
    "        plt.grid(True)\n",
    "        plt.tick_params(labelleft=False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        plt.clf() # limpa a imagem do gráfico\n",
    "\n",
    "regr = linear_regr1(learning_rate=0.0003, training_iters=40, show_learning=True)\n",
    "regr.fit(dados['x'], dados['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando melhorias: acelerando GDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDE por si só é um método bastante popular para treinar modelos de Aprendizagem de Máquina. Mesmo assim, várias extensões e variações foram porpostas com o intuito de diminuir as flutuações na função custo ou acelerar o processo de treinamento.\n",
    "\n",
    "A idéa é acelerar o processo de aprendizado por GDE quando estamos indo na diereção certa.\n",
    "\n",
    "É fácil modificar o GDE para incorporar o momento. Para isso, basta sabermos a velocidade passada da bolinha e atualizá-la conforme o processo de descida. Além disso, nós agora vamos atualizar os pâmetros confrome a velocidade, em vez de utilizar apenas o gradiente. \n",
    "$$\\pmb{v_t} := \\gamma \\pmb{v_{t-1}} + \\alpha \\nabla(L)) $$$$\\pmb{\\hat{w}} := \\pmb{\\hat{w}} - \\pmb{v_t}$$\n",
    "\n",
    "Na primeira linha, nós atualizamos a velocidade. O termo $\\gamma v_{t-1}$ funciona como um atrito ou resistência do ar, diminuindo a velocidade em uma porcentagem $1-\\gamma$ da velocidade anterior. $\\gamma$ é mais um hiper-parâmetro que precisa ser ajustado manualmente. O termo seguinte, $\\alpha  \\nabla(L))$, incorpora a informação da inclinação descida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "class linear_regr2(object):\n",
    "\n",
    "    def __init__(self, learning_rate=0.0001, training_iters=1000, gamma=0.9, batch_size=10, show_learning=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.training_iters = training_iters\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.show_learning = show_learning\n",
    "        \n",
    "    def fit(self, X_train, y_train, plot=False):\n",
    "        \n",
    "        # formata os dados\n",
    "        if len(X_train.values.shape) < 2:\n",
    "            X = X_train.values.reshape(-1,1)\n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "        # para plotar o aprendizado (é preciso conhecer a equação geradora)\n",
    "        if self.show_learning:\n",
    "            assert X.shape[1] <= 2 # só é possível viazualizar 2 parâmetros\n",
    "            self.w1_loss = [L(y_train, 5 + i * X_train) for i in np.linspace(0,6,20)]\n",
    "            self.b_loss = [L(y_train, i + 3 * X_train) for i in np.linspace(-10,20,20)]\n",
    "        \n",
    "        # inicia os parâmetros com pequenos valores aleatórios (nosso chute razoável)\n",
    "        self.w_hat = np.random.normal(0,5, size = X[0].shape)\n",
    "        \n",
    "        velocidade =  np.zeros(self.w_hat.shape) # inicia a velocidade\n",
    "        loss = [] # para plotar o aprendizado\n",
    "        for i in range(self.training_iters):\n",
    "            \n",
    "            # cria os mini-lotes\n",
    "            offset = (i * self.batch_size) % (y_train.shape[0] - self.batch_size)\n",
    "            batch_X = X[offset:(offset + self.batch_size), :]\n",
    "            batch_y = y_train[offset:(offset + self.batch_size)]\n",
    "            \n",
    "            gradient = np.zeros(self.w_hat.shape) # inicia o gradiente\n",
    "            \n",
    "            # atualiza o gradiente com informação de todos os pontos\n",
    "            for point, yi in zip(batch_X, batch_y):\n",
    "                gradient +=  (point * self.w_hat - yi) * point\n",
    "            \n",
    "            gradient *= self.learning_rate # multiplica o gradiente pela taxa de aprendizado\n",
    "            velocidade = (velocidade * self.gamma) + gradient # atualiza a velocidade\n",
    "            \n",
    "            # atualiza os parâmetros\n",
    "            self.w_hat -= velocidade\n",
    "            \n",
    "            l = ((y_train - self.predict(X_train)) ** 2).sum() # calcula o custo\n",
    "                        \n",
    "            loss.append(l) # armazeno o custo para gráfico\n",
    "        \n",
    "            if self.show_learning:\n",
    "                # mostra o estado atual do aprendizado\n",
    "                self._show_state(X_train, y_train, loss) \n",
    "            \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        # formata os dados\n",
    "        if len(X_test.values.shape) < 2:\n",
    "            X = X_test.values.reshape(-1,1)\n",
    "        X = np.insert(X, 0, 1, 1)\n",
    "        \n",
    "        return np.dot(X, self.w_hat) \n",
    "    \n",
    "    \n",
    "    def _show_state(self, X_train, y_train, loss):\n",
    "        # visualiza o processo de aprendizado\n",
    "        lb = L(y_train, self.w_hat[0] + 3 * X_train) # calcula o custo na direção b\n",
    "        lw = L(y_train, 5 + self.w_hat[1] * X_train) # calcula o custo na direção w\n",
    "\n",
    "        # scatter plot\n",
    "        plt.subplot(221)\n",
    "        plt.scatter(X_train, y_train, s= 10)\n",
    "        plt.plot(X_train, self.predict(X_train), c='r')\n",
    "        plt.title('$y = b + w x$')\n",
    "        plt.tick_params(labelsize=9, labelleft=False, labelbottom = False)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # loss\n",
    "        plt.subplot(222)\n",
    "        plt.plot(range(len(loss)), loss)\n",
    "        plt.title('Custo')\n",
    "        plt.tick_params(labelsize=9, labelleft=False, labelbottom = False)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # b_loss\n",
    "        plt.subplot(223)\n",
    "        plt.plot( np.linspace(-10,20,20), self.b_loss)\n",
    "        plt.scatter(self.w_hat[0], lb, c = 'k')\n",
    "        plt.title('Custo em $\\hat{b}$')\n",
    "        plt.tick_params(labelleft=False)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # w_loss\n",
    "        plt.subplot(224)\n",
    "        plt.plot(np.linspace(0,6,20), self.w1_loss)\n",
    "        plt.scatter(self.w_hat[1], lw, c = 'k')\n",
    "        plt.title('Custo em $\\hat{w}$')\n",
    "        plt.grid(True)\n",
    "        plt.tick_params(labelleft=False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        plt.clf() # limpa a imagem do gráfico\n",
    "\n",
    "regr = linear_regr2(learning_rate=0.0001, training_iters=30, gamma = 0.9, show_learning=True)\n",
    "regr.fit(dados['x'], dados['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando o Gradiente Descendente na prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
